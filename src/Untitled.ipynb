{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71f4189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from langchain.llms import Cohere, OpenAI, AI21\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import SequentialChain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.embeddings import CohereEmbeddings,OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import DataFrameLoader,CSVLoader\n",
    "import os\n",
    "\n",
    "with open(\"../data/apis.yaml\", \"r\") as file:\n",
    "    yaml_data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "open_ai_params = {\n",
    "    \"max_tokens\": 512,\n",
    "    \"openai_api_key\": yaml_data[\"LLMS\"][\"OPENAI_API_KEY\"],\n",
    "}\n",
    "cohere_params = {\n",
    "    \"model\": \"command-xlarge-nightly\",\n",
    "    \"max_tokens\": 2202,\n",
    "    \"cohere_api_key\": yaml_data[\"LLMS\"][\"COHERE_API_KEY\"],\n",
    "    \"temperature\": 0,\n",
    "    \"k\": 0,\n",
    "}\n",
    "ai21_params = {\n",
    "    \"model\": \"j2-jumbo-instruct\",\n",
    "    \"numResults\": 1,\n",
    "    \"temperature\": 0,\n",
    "    \"topP\": 1,\n",
    "    \"ai21_api_key\": yaml_data[\"LLMS\"][\"AI21_API_KEY\"],\n",
    "    \"maxTokens\": 5000,\n",
    "}\n",
    "\n",
    "anthropic_params = {\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88ccbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key = open_ai_params[\"openai_api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "19cc14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from langchain.llms import Cohere, OpenAI, AI21\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import SequentialChain,AnalyzeDocumentChain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.embeddings import CohereEmbeddings,OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.document_loaders import DataFrameLoader,CSVLoader,SeleniumURLLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import pypdf\n",
    "import os\n",
    "\n",
    "with open(\"../data/apis.yaml\", \"r\") as file:\n",
    "    yaml_data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "open_ai_params = {\n",
    "    \"max_tokens\": 512,\n",
    "    \"openai_api_key\": yaml_data[\"LLMS\"][\"OPENAI_API_KEY\"],\n",
    "}\n",
    "cohere_params = {\n",
    "    \"model\": \"command-xlarge-nightly\",\n",
    "    \"max_tokens\": 2202,\n",
    "    \"cohere_api_key\": yaml_data[\"LLMS\"][\"COHERE_API_KEY\"],\n",
    "    \"temperature\": 0,\n",
    "    \"k\": 0,\n",
    "}\n",
    "# ai21_params = {\n",
    "#     \"model\": \"j2-jumbo-instruct\",\n",
    "#     \"numResults\": 1,\n",
    "#     \"temperature\": 0,\n",
    "#     \"topP\": 1,\n",
    "#     \"ai21_api_key\": yaml_data[\"LLMS\"][\"AI21_API_KEY\"],\n",
    "#     \"maxTokens\": 25,\n",
    "# }\n",
    "\n",
    "claude_params = {'anthropic_api_key':'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',\n",
    "                'model':'claude-instant-v1.1-100k','max_tokens_to_sample':30000}\n",
    "\n",
    "chat = ChatAnthropic(**claude_params)\n",
    "\n",
    "\n",
    "class StockLLM:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "\n",
    "    def stock_availability(self):\n",
    "        return self.ticker in os.listdir(\"./ticker\")\n",
    "\n",
    "    def sec_analysis_agent(self):\n",
    "        ### Get sec files\n",
    "        file_path = f\"../ticker/{self.ticker}/fa/analysis_sec.txt\"\n",
    "        try:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                file = f.read()\n",
    "        except:\n",
    "            raise Exception(\"This file is unavailable\")\n",
    "        return file\n",
    "\n",
    "class LLM_analysis:\n",
    "    def __init__(self, ticker, open_ai_params, cohere_params,claude_params):\n",
    "        ### Requires both Cohere and OpenAI APIs\n",
    "        self.ticker = ticker\n",
    "        self.open_ai_params = open_ai_params\n",
    "        self.cohere_params = cohere_params\n",
    "        self.claude_params = claude_params\n",
    "        self.cohere_llm = Cohere(**self.cohere_params)\n",
    "        self.open_ai_llm = OpenAI(**self.open_ai_params)\n",
    "        self.claude_llm = ChatAnthropic(**claude_params)\n",
    "        self.stockllm = StockLLM(self.ticker)\n",
    "\n",
    "    def sec_chain_analysis(self):\n",
    "        ### Initally we need a good bullet point summary of the latest sec filings\n",
    "\n",
    "        template = \"\"\"\n",
    "\"This is the sec summary of {stock}.\\n\n",
    "{summary}\\n\"\n",
    "Can you summarize the text into bullet points with numbers in detail. Be as detailed as possible:-\n",
    "\"\"\"\n",
    "        sec_template = PromptTemplate(\n",
    "            template=template, input_variables=[\"stock\", \"summary\"]\n",
    "        )\n",
    "        sec_chain = LLMChain(\n",
    "            llm=self.cohere_llm, prompt=sec_template, output_key=\"sec_summary\"\n",
    "        )\n",
    "        template = \"\"\"You are a financial analyst. Based on the below bullet points, can you further separate them into positive\n",
    "and negative news in bullet points. Please do not leave out any point and go step by step.\n",
    "{sec_summary}\"\"\"\n",
    "        pos_neg_template = PromptTemplate(\n",
    "            template=template, input_variables=[\"sec_summary\"]\n",
    "        )\n",
    "        pos_neg_chain = LLMChain(\n",
    "            llm=self.open_ai_llm, prompt=pos_neg_template, output_key=\"sec_final_output\"\n",
    "        )\n",
    "        overall_chain = SequentialChain(\n",
    "            input_variables=[\"stock\", \"summary\"],\n",
    "            chains=[sec_chain, pos_neg_chain],\n",
    "            # Here we return multiple variables\n",
    "            output_variables=[\"sec_final_output\", \"sec_summary\"],\n",
    "            verbose=True,\n",
    "        )\n",
    "        with get_openai_callback() as cb:\n",
    "            statement = overall_chain(\n",
    "                {\"stock\": self.ticker, \"summary\": self.stockllm.sec_analysis_agent()}\n",
    "            )\n",
    "            cb = {\n",
    "                \"Total Tokens\": cb.total_tokens,\n",
    "                \"Prompt Tokens\": cb.prompt_tokens,\n",
    "                \"Completion Tokens\": cb.completion_tokens,\n",
    "                \"Total Cost (USD)\": cb.total_cost,\n",
    "            }\n",
    "            statement[\"token_summary\"] = cb\n",
    "        return statement\n",
    "\n",
    "    def input_from_user_zero_shot(self, query):\n",
    "        ### Zero shot learning \n",
    "        template = \"\"\"\n",
    "\"\\n\n",
    "{summary}\\n\"\n",
    "Please predict sentiment classification of the above based on above text where sentiment can only be Strongly Positive, Positive, Strongly Negative, Negative, or Neutral. Only output the sentiment class, should be 1 or 2 words.:-\n",
    "\"\"\"\n",
    "        sec_template = PromptTemplate(template=template, input_variables=[\"summary\"])\n",
    "        return self.open_ai_llm(template.format(summary=query))\n",
    "    \n",
    "    def input_from_user_embedding_shot(self,query):\n",
    "        classifications = ['Strongly Positive','Positive','Neutral','Negative','Strongly Negative']\n",
    "        ### Create embeddings\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key = open_ai_params[\"openai_api_key\"])\n",
    "        ## Create a faiss vector database\n",
    "        faiss_classifications = FAISS.from_texts(classifications,embeddings)\n",
    "        text = faiss_classifications.similarity_search_with_score(query,k = 1)[0][0].page_content\n",
    "        return text\n",
    "        \n",
    "    def input_from_user_sentiment_file(self,file,type_of_file):\n",
    "        if type_of_file not in ['pdf','txt','link','csv']:\n",
    "            raise NotImplementedError(\"This file extension has not been implemented.\")\n",
    "        if type_of_file == 'pdf':\n",
    "            pages = [page.extract_text() for page in pypdf.PdfReader(file).pages]\n",
    "            text = '\\n'.join(pages)\n",
    "\n",
    "        if type_of_file in ['txt','csv']:\n",
    "            with open(file,'r') as f:\n",
    "                text = f.read()\n",
    "        \n",
    "        if type_of_file == 'link':\n",
    "            loader = SeleniumURLLoader(urls=[file])\n",
    "            data = loader.load()\n",
    "            text = data[0].page_content\n",
    "        llm = AI21(temperature=0,ai21_api_key = ai21_params[\"ai21_api_key\"])\n",
    "        summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)\n",
    "        summary = summarize_document_chain.run(text)\n",
    "        final_class = self.input_from_user_embedding_shot(summary)\n",
    "        return final_class\n",
    "    \n",
    "    def query_user(self,file,type_of_file):\n",
    "        if type_of_file not in ['pdf','txt','link','csv']:\n",
    "            raise NotImplementedError(\"This file extension has not been implemented.\")\n",
    "        if type_of_file == 'pdf':\n",
    "            pages = [page.extract_text() for page in pypdf.PdfReader(file).pages]\n",
    "            text = '\\n'.join(pages)\n",
    "\n",
    "        if type_of_file in ['txt','csv']:\n",
    "            with open(file,'r') as f:\n",
    "                text = f.read()\n",
    "        \n",
    "        if type_of_file == 'link':\n",
    "            loader = SeleniumURLLoader(urls=[file])\n",
    "            data = loader.load()\n",
    "            text = data[0].page_content\n",
    "        llm = AI21(temperature=0,ai21_api_key = ai21_params[\"ai21_api_key\"])\n",
    "        summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)\n",
    "        summary = summarize_document_chain.run(text)\n",
    "        final_class = self.input_from_user_embedding_shot(summary)\n",
    "        return final_class\n",
    "    \n",
    "    def context_precursor(self):\n",
    "        if self.ticker is not None:\n",
    "            entire_context = []\n",
    "            for file in sorted(os.listdir('../ticker/{}/fa'.format(self.ticker))):\n",
    "                if file == 'analysis_sec.txt':\n",
    "                    with open('../ticker/{}/fa/analysis_sec.txt'.format(self.ticker),'r') as f:\n",
    "                        x = f.read()\n",
    "                        context_precursor = '''Here are the summary of the latest SEC filings figures\\n'''\n",
    "                        final_context = context_precursor + x\n",
    "                        entire_context.append(final_context)\n",
    "                elif file == 'est.csv':\n",
    "                    with open('../ticker/{}/fa/est.csv'.format(self.ticker),'r') as f:\n",
    "                        x = f.read()\n",
    "                        context_precursor = '''Here are some analyst estimates from Business Insider\\n'''\n",
    "                        final_context = context_precursor + x\n",
    "                        entire_context.append(final_context)\n",
    "                elif file == 'income.csv':\n",
    "                    with open('../ticker/{}/fa/income.csv'.format(self.ticker),'r') as f:\n",
    "                        x = f.read()\n",
    "                        context_precursor = '''Here are the income statement figures\\n'''\n",
    "                        final_context = context_precursor + x\n",
    "                        entire_context.append(final_context)\n",
    "                elif file == 'balance.csv':\n",
    "                    with open('../ticker/{}/fa/balance.csv'.format(self.ticker),'r') as f:\n",
    "                        x = f.read()\n",
    "                        context_precursor = '''Here are the balance sheet statement figures\\n'''\n",
    "                        final_context = context_precursor + x\n",
    "                        entire_context.append(final_context)\n",
    "                elif file == 'cash.csv':\n",
    "                    with open('../ticker/{}/fa/cash.csv'.format(self.ticker),'r') as f:\n",
    "                        x = f.read()\n",
    "                        context_precursor = '''Here are the cash flow statement figures\\n'''\n",
    "                        final_context = context_precursor + x\n",
    "                        entire_context.append(final_context)\n",
    "                elif file == 'ratios.csv':\n",
    "                    with open('../ticker/{}/fa/ratios.csv'.format(self.ticker),'r') as f:\n",
    "                        x = f.read()\n",
    "                        context_precursor = '''Here are the financial ratios statement figures\\n'''\n",
    "                        final_context = context_precursor + x\n",
    "                        entire_context.append(final_context)\n",
    "                elif file == 'fraud.csv':\n",
    "                    with open('../ticker/{}/fa/fraud.csv'.format(self.ticker),'r') as f:\n",
    "                        x = f.read()\n",
    "                        context_precursor = '''Here are the fraud ratios statement figures\\n'''\n",
    "                        final_context = context_precursor + x\n",
    "                        entire_context.append(final_context)\n",
    "\n",
    "            if os.path.exists('../ticker/{}/news/c_news.csv'.format(self.ticker)):\n",
    "                x = pd.read_csv('../ticker/{}/news/c_news.csv'.format(self.ticker))\n",
    "                x['datetime'] = pd.to_datetime(x['datetime'])\n",
    "                datetimemax = x['datetime'].max()\n",
    "                datetimemin = datetimemax + relativedelta(days = -7)\n",
    "                x = '\\n'.join(list(x[(x['datetime'] >= datetimemin) & (x['datetime'] <= datetimemax)].head(10)['headline']))\n",
    "                context_precursor = '''Here are some recent news\\n'''\n",
    "                final_context = context_precursor + x\n",
    "                entire_context.append(final_context)\n",
    "\n",
    "            entire_context = '\\n\\n'.join(entire_context)\n",
    "            self.entire_context = entire_context\n",
    "            \n",
    "    def qachain_anthropic(self,vectorstore,query):\n",
    "        if self.ticker == None:\n",
    "            self.context_precursor()\n",
    "            filter_dict = {'$and':[{'metadata':{'$ne':'Sentiment News'}}]}\n",
    "            documents = vectorstore.as_retriever(search_kwargs={\"k\": 5,'filter':filter_dict}).get_relevant_documents(query)\n",
    "        else:\n",
    "            filter_dict = {'$and':[{'ticker':self.ticker},{'metadata':{'$ne':'Sentiment News'}}]}\n",
    "            documents = vectorstore.as_retriever(search_kwargs={\"k\": 5,'filter':filter_dict}).get_relevant_documents(query)\n",
    "            #documents = vectorstore.similarity_search(query,k = 1,filter = {'ticker':self.ticker})\n",
    "        #documents = vectorstore.as_retriever(search_kwargs={\"k\": 1}).get_relevant_documents(query)\n",
    "        k_count = max(len(set([doc.metadata['file_path'] for doc in documents])),3)*5\n",
    "        if k_count != 5:\n",
    "            documents = vectorstore.as_retriever(search_kwargs={\"k\": k_count,'filter':filter_dict}).get_relevant_documents(query)\n",
    "\n",
    "        file_names = [doc.metadata['file_path'] for doc in documents]\n",
    "\n",
    "        prompt = '''Use the following information to answer the question at the end in a coherent summary. \n",
    "    The below contains information about {ticker} and you are a financial analyst\n",
    "    {context_precursor}\n",
    "    Question: {question}\n",
    "    Think step by step and be as detailed as possible. \n",
    "    Do not mention anything in your response about the context/information'''.format(ticker = self.ticker,context_precursor = self.entire_context,question = query )\n",
    "        return prompt,file_names\n",
    "    def qachain(self,vectorstore,query):\n",
    "        if self.ticker == None:\n",
    "            filter_dict = {'$and':[{'metadata':{'$ne':'Sentiment News'}}]}\n",
    "            documents = vectorstore.as_retriever(search_kwargs={\"k\": 5,'filter':filter_dict}).get_relevant_documents(query)\n",
    "        else:\n",
    "            filter_dict = {'$and':[{'ticker':self.ticker},{'metadata':{'$ne':'Sentiment News'}}]}\n",
    "            documents = vectorstore.as_retriever(search_kwargs={\"k\": 5,'filter':filter_dict}).get_relevant_documents(query)\n",
    "            #documents = vectorstore.similarity_search(query,k = 1,filter = {'ticker':self.ticker})\n",
    "        #documents = vectorstore.as_retriever(search_kwargs={\"k\": 1}).get_relevant_documents(query)\n",
    "        k_count = max(len(set([doc.metadata['file_path'] for doc in documents])),3)*5\n",
    "        if k_count != 5:\n",
    "            documents = vectorstore.as_retriever(search_kwargs={\"k\": k_count,'filter':filter_dict}).get_relevant_documents(query)\n",
    "\n",
    "\n",
    "    #page_content = vectorstore.as_retriever(search_kwargs={\"k\": 10}).get_relevant_documents(query)\n",
    "        page_content = '\\n\\n'.join([doc.page_content for doc in documents])\n",
    "        file_names = [doc.metadata['file_path'] for doc in documents]\n",
    "        meta_data = documents[0].metadata\n",
    "       # file_path = \n",
    "        context_precursor =  '''The below contains information about {} and you are a financial analyst'''.format(meta_data['ticker'])\n",
    "       # import pdb;pdb.set_trace()\n",
    "        prompt_template = \"\"\"Use the following information to answer the question at the end in a coherent summary. \n",
    "    {context_precursor}\n",
    "    {page_content}\n",
    "    Question: {question}\n",
    "    Think step by step.Do not mention \"As per the information or context\" in your response.\n",
    "    \"\"\"\n",
    "        prompt = prompt_template.format(context_precursor = context_precursor,page_content = page_content,question = query)\n",
    "        context_full_doc = []\n",
    "        return prompt,file_names\n",
    "    \n",
    "    def process_file_names(self,file_names):\n",
    "        csv_filter = [file_name for file_name in file_names if '.csv' in file_name]\n",
    "        df = pd.read_csv(csv_filter[0])\n",
    "        df.rename(columns = {'Unnamed: 0':'Description'},inplace = True)\n",
    "        return df       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ac064174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import FAISS,Pinecone\n",
    "oai = OpenAIEmbeddings(openai_api_key = open_ai_params['openai_api_key'])\n",
    "index_name = \"financial-analysis\"\n",
    "pinecone.init(api_key= yaml_data['PINECONE']['API_KEY'],environment= yaml_data['PINECONE']['ENV'])\n",
    "pinecone_db = Pinecone.from_existing_index('financial-analysis', oai)\n",
    "x = LLM_analysis('AAPL',open_ai_params,cohere_params,claude_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c8a83f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.context_precursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "57ac07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query,filenames = x.qachain_anthropic(pinecone_db,'''Is AAPL a good stock to buy?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1d1f2d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided, here are the key factors I would consider in determining if AAPL is a good stock to buy:\n",
      "\n",
      "1. Revenue and earnings growth: AAPL has been reporting steady revenue growth over the past few years, with analysts projecting continued growth in the coming years. However, earnings growth has been relatively flat. Revenue growth is a good sign, but slower earnings growth could be a concern.  \n",
      "\n",
      "2. Profit margins: AAPL's gross and operating profit margins have been relatively stable in the mid-30% to low 40% range. This indicates efficient operations and pricing power. However, net profit margins have been slightly trending down in recent years. The company will need to manage costs to maintain or improve margins going forward.\n",
      "\n",
      "3. Cash flow: AAPL generates strong operating and free cash flow, which provides financial flexibility. However, a large portion of that cash flow has been used to repurchase shares and pay dividends rather than investing for growth. The company will need to invest in new growth drivers to support future performance.\n",
      "\n",
      "4. Valuation: Based on P/E, P/S, and P/CF ratios, AAPL's valuation multiple is higher than historical averages. This indicates that the stock price already reflects high expectations for future performance. AAPL will need to execute well to achieve those expectations and justify its premium valuation.  \n",
      "\n",
      "5. Dependence on iPhone: The iPhone still accounts for over 50% of AAPL's revenues. While iPhone sales have been growing, the company's reliance on a single product could be a risk. AAPL will need to continue expanding its services, wearables, and other businesses to diversify revenues.\n",
      "\n",
      "In summary, while AAPL has many strengths, its slower earnings growth, potential margins pressures, high valuation multiples, and iPhone dependence could limit upside potential. The company would need to execute well on managing costs, investing for growth, and diversifying beyond the iPhone to justify being a \"good\" buy at current prices. The balance of positives and risks likely makes AAPL a hold rather than a clear buy at this time.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=query)\n",
    "]\n",
    "print(chat(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c0d9d7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is an elaboration on Apple's debt levels:\n",
      "\n",
      "• Apple (AAPL) has a relatively low debt level compared to most companies. As of June 2022, Apple had a total debt of $91 billion. This includes long-term debt of $78 billion and short-term debt of $13 billion.\n",
      "\n",
      "• Apple generates massive cash flows from operations. In its most recent quarter (Q3 2022), Apple reported operating cash flow of $25 billion. This allows the company to fund most of its operations, investments and dividend payments from its cash flows, limiting the need for additional debt.\n",
      "\n",
      "• Apple's debt to equity ratio is relatively low at 0.2, indicating that for every $1 of shareholders' equity, the company has $0.2 in debt. This is considered a low leverage ratio. Most companies have debt to equity ratios above 1.\n",
      "\n",
      "• Apple maintains a very high credit rating from the major rating agencies. As of 2022, Apple has a AA+ rating from S&P and an AAA rating from Fitch, indicating the company has an extremely strong capacity to meet its financial commitments. These high ratings allow Apple to borrow money at low interest rates.\n",
      "\n",
      "• Apple's large cash pile of $200+ billion also gives the company flexibility to take on additional debt if needed to fund acquisitions, stock buybacks or other investments. However, with Apple's strong cash flows and low debt levels, additional borrowing has not been necessary in recent years.\n",
      "\n",
      "So in summary, while Apple does have some debt on its balance sheet, the company's overall debt levels are relatively low compared to many of its industry peers. Apple's massive cash flows and high cash reserves have allowed the company to operate with a conservative amount of leverage.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content='Elaborate on the debt levels of AAPL?')\n",
    "]\n",
    "print(chat(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a1ca22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_context = []\n",
    "for file in sorted(os.listdir('../ticker/{}/fa'.format('AAPL'))):\n",
    "    if file == 'analysis_sec.txt':\n",
    "        with open('../ticker/{}/fa/analysis_sec.txt'.format('AAPL'),'r') as f:\n",
    "            x = f.read()\n",
    "            context_precursor = '''Here are the summary of the latest SEC filings figures\\n'''\n",
    "            final_context = context_precursor + x\n",
    "            entire_context.append(final_context)\n",
    "    elif file == 'est.csv':\n",
    "        with open('../ticker/{}/fa/est.csv'.format('AAPL'),'r') as f:\n",
    "            x = f.read()\n",
    "            context_precursor = '''Here are some analyst estimates from Business Insider\\n'''\n",
    "            final_context = context_precursor + x\n",
    "            entire_context.append(final_context)\n",
    "    elif file == 'income.csv':\n",
    "        with open('../ticker/{}/fa/income.csv'.format('AAPL'),'r') as f:\n",
    "            x = f.read()\n",
    "            context_precursor = '''Here are the income statement figures\\n'''\n",
    "            final_context = context_precursor + x\n",
    "            entire_context.append(final_context)\n",
    "    elif file == 'balance.csv':\n",
    "        with open('../ticker/{}/fa/balance.csv'.format('AAPL'),'r') as f:\n",
    "            x = f.read()\n",
    "            context_precursor = '''Here are the balance sheet statement figures\\n'''\n",
    "            final_context = context_precursor + x\n",
    "            entire_context.append(final_context)\n",
    "    elif file == 'cash.csv':\n",
    "        with open('../ticker/{}/fa/cash.csv'.format('AAPL'),'r') as f:\n",
    "            x = f.read()\n",
    "            context_precursor = '''Here are the cash flow statement figures\\n'''\n",
    "            final_context = context_precursor + x\n",
    "            entire_context.append(final_context)\n",
    "    elif file == 'ratios.csv':\n",
    "        with open('../ticker/{}/fa/ratios.csv'.format('AAPL'),'r') as f:\n",
    "            x = f.read()\n",
    "            context_precursor = '''Here are the financial ratios statement figures\\n'''\n",
    "            final_context = context_precursor + x\n",
    "            entire_context.append(final_context)\n",
    "    elif file == 'fraud.csv':\n",
    "        with open('../ticker/{}/fa/fraud.csv'.format('AAPL'),'r') as f:\n",
    "            x = f.read()\n",
    "            context_precursor = '''Here are the fraud ratios statement figures\\n'''\n",
    "            final_context = context_precursor + x\n",
    "            entire_context.append(final_context)\n",
    "            \n",
    "if os.path.exists('../ticker/{}/news/c_news.csv'.format('AAPL')):\n",
    "    x = pd.read_csv('../ticker/{}/news/c_news.csv'.format('AAPL'))\n",
    "    x['datetime'] = pd.to_datetime(x['datetime'])\n",
    "    datetimemax = x['datetime'].max()\n",
    "    datetimemin = datetimemax + relativedelta(days = -7)\n",
    "    x = '\\n'.join(list(x[(x['datetime'] >= datetimemin) & (x['datetime'] <= datetimemax)].head(10)['headline']))\n",
    "    context_precursor = '''Here are some recent news\\n'''\n",
    "    final_context = context_precursor + x\n",
    "    entire_context.append(final_context)\n",
    "\n",
    "entire_context = '\\n\\n'.join(entire_context)\n",
    "    \n",
    "    #context_precursor = \n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ab23b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/43/fjcrjx8d7y51hzt_tn2d9z_40000gn/T/ipykernel_14958/3369489098.py\u001b[0m(189)\u001b[0;36mqachain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    187 \u001b[0;31m            \u001b[0;31m#documents = vectorstore.similarity_search(query,k = 1,filter = {'ticker':self.ticker})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m        \u001b[0;31m#documents = vectorstore.as_retriever(search_kwargs={\"k\": 1}).get_relevant_documents(query)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 189 \u001b[0;31m        \u001b[0mk_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mk_count\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    191 \u001b[0;31m            \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'filter'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfilter_dict\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "query,dataframe = x.qachain(pinecone_db,'''Is ABT a good buy?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01fccbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following information to answer the question at the end in a coherent summary. \n",
      "    The below contains information about ABT and you are a financial analyst\n",
      "    : Other short-term investments(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 288.0\n",
      "2021-12-31: 450.0\n",
      "2020-12-31: 310.0\n",
      "2019-12-31: 280.0\n",
      "\n",
      ": P/E Ratio\n",
      "ticker: ABT\n",
      "2023: 25.42\n",
      "2024: 24.21\n",
      "2025: 21.55\n",
      "2026: 19.68\n",
      "2027: 18.23\n",
      "\n",
      ": Taxes payable(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 343.0\n",
      "2021-12-31: 306.0\n",
      "2020-12-31: 362.0\n",
      "2019-12-31: 226.0\n",
      "\n",
      ": Total Assets(In $M)\n",
      "ticker: ABT\n",
      "2023: 77,406\n",
      "2024: 79,956\n",
      "2025: 81,503\n",
      "2026: 97,735\n",
      "2027: 105,142\n",
      "\n",
      ": Selling, General & Admin. Exp.(In $M)\n",
      "ticker: ABT\n",
      "2023: 10,937\n",
      "2024: 11,453\n",
      "2025: 12,074\n",
      "2026: 12,756\n",
      "2027: 13,491\n",
      "\n",
      ": Equity and other investments(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 766.0\n",
      "2021-12-31: 816.0\n",
      "2020-12-31: 821.0\n",
      "2019-12-31: 883.0\n",
      "\n",
      ": Goodwill(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 22799.0\n",
      "2021-12-31: 23231.0\n",
      "2020-12-31: 23744.0\n",
      "2019-12-31: 23195.0\n",
      "\n",
      ": Price fair value\n",
      "2022: 5.301\n",
      "2021: 6.935\n",
      "2020: 5.915\n",
      "2019: 4.924\n",
      "2018: 4.160\n",
      "ticker: ABT\n",
      "\n",
      ": EBIT(In $M)\n",
      "ticker: ABT\n",
      "2023: 8,794\n",
      "2024: 9,296\n",
      "2025: 10,385\n",
      "2026: 11,302\n",
      "2027: 12,284\n",
      "\n",
      ": Dividend\n",
      "ticker: ABT\n",
      "2023: 1.96\n",
      "2024: 2.07\n",
      "2025: 2.22\n",
      "2026: 2.61\n",
      "2027: -\n",
      "\n",
      ": Revenue(In $M)\n",
      "ticker: ABT\n",
      "2023: 39,616\n",
      "2024: 41,450\n",
      "2025: 44,399\n",
      "2026: 47,817\n",
      "2027: 50,310\n",
      "\n",
      ": Pre-Tax Profit(In $M)\n",
      "ticker: ABT\n",
      "2023: 8,964\n",
      "2024: 9,376\n",
      "2025: 10,467\n",
      "2026: 11,387\n",
      "2027: 12,409\n",
      "\n",
      ": Net Profit(In $M)\n",
      "ticker: ABT\n",
      "2023: 7,712\n",
      "2024: 8,055\n",
      "2025: 8,980\n",
      "2026: 9,924\n",
      "2027: 10,672\n",
      "\n",
      ": Dividend Yield (in %)\n",
      "ticker: ABT\n",
      "2023: 1.99 %\n",
      "2024: 2.12 %\n",
      "2025: 2.44 %\n",
      "2026: 2.57 %\n",
      "2027: -\n",
      "\n",
      ": Purchases of investments(figures in $M)\n",
      "ttm: -185.0\n",
      "2022-12-31: -185.0\n",
      "2021-12-31: -173.0\n",
      "2020-12-31: -83.0\n",
      "2019-12-31: -103.0\n",
      "ticker: ABT\n",
      "\n",
      ": Income before tax(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: 8306.0\n",
      "2022-12-31: 8306.0\n",
      "2021-12-31: 8211.0\n",
      "2020-12-31: 4968.0\n",
      "2019-12-31: 4077.0\n",
      "\n",
      ": Cash Flow from Investing(In $M)\n",
      "ticker: ABT\n",
      "2023: -1,649\n",
      "2024: -1,806\n",
      "2025: -1,932\n",
      "2026: -2,702\n",
      "2027: -2,896\n",
      "\n",
      ": EPS\n",
      "ticker: ABT\n",
      "2023: 4.40\n",
      "2024: 4.62\n",
      "2025: 5.19\n",
      "2026: 5.69\n",
      "2027: 6.14\n",
      "\n",
      ": Intangible assets(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 10454.0\n",
      "2021-12-31: 12739.0\n",
      "2020-12-31: 14784.0\n",
      "2019-12-31: 17025.0\n",
      "\n",
      ": Total liabilities and stockholders' equity(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 74438.0\n",
      "2021-12-31: 75196.0\n",
      "2020-12-31: 72548.0\n",
      "2019-12-31: 67887.0\n",
      "\n",
      ": Research & Development Exp.(In $M)\n",
      "ticker: ABT\n",
      "2023: 2,513\n",
      "2024: 2,642\n",
      "2025: 2,799\n",
      "2026: 2,925\n",
      "2027: 3,206\n",
      "\n",
      ": Long-term debt(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 14522.0\n",
      "2021-12-31: 17296.0\n",
      "2020-12-31: 18527.0\n",
      "2019-12-31: 16661.0\n",
      "\n",
      ": Capital Expenditure(In $M)\n",
      "ticker: ABT\n",
      "2023: 1,718\n",
      "2024: 1,837\n",
      "2025: 1,918\n",
      "2026: 2,284\n",
      "2027: 2,641\n",
      "\n",
      ": Gross Income(In $M)\n",
      "ticker: ABT\n",
      "2023: 22,249\n",
      "2024: 23,476\n",
      "2025: 25,290\n",
      "2026: 26,970\n",
      "2027: 28,980\n",
      "\n",
      ": Total assets(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 74438.0\n",
      "2021-12-31: 75196.0\n",
      "2020-12-31: 72548.0\n",
      "2019-12-31: 67887.0\n",
      "\n",
      ": Operating income or loss(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: 8362.0\n",
      "2022-12-31: 8362.0\n",
      "2021-12-31: 8425.0\n",
      "2020-12-31: 5357.0\n",
      "2019-12-31: 4532.0\n",
      "\n",
      ": Total non-current assets(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 49214.0\n",
      "2021-12-31: 50957.0\n",
      "2020-12-31: 52107.0\n",
      "2019-12-31: 52220.0\n",
      "\n",
      ": Price book value ratio\n",
      "2022: 5.301\n",
      "2021: 6.935\n",
      "2020: 5.915\n",
      "2019: 4.924\n",
      "2018: 4.160\n",
      "ticker: ABT\n",
      "\n",
      ": Inventory(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 6173.0\n",
      "2021-12-31: 5157.0\n",
      "2020-12-31: 5012.0\n",
      "2019-12-31: 4316.0\n",
      "\n",
      ": Net income(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: 6933.0\n",
      "2022-12-31: 6933.0\n",
      "2021-12-31: 7071.0\n",
      "2020-12-31: 4495.0\n",
      "2019-12-31: 3687.0\n",
      "\n",
      ": Current debt(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 2251.0\n",
      "2021-12-31: 754.0\n",
      "2020-12-31: 220.0\n",
      "2019-12-31: 1478.0\n",
      "\n",
      ": Book Value per Share(In $)\n",
      "ticker: ABT\n",
      "2023: 22.66\n",
      "2024: 23.52\n",
      "2025: 24.64\n",
      "2026: -\n",
      "2027: -\n",
      "\n",
      ": Total stockholders' equity(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 36686.0\n",
      "2021-12-31: 35802.0\n",
      "2020-12-31: 32784.0\n",
      "2019-12-31: 31088.0\n",
      "\n",
      ": Common stock(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 24709.0\n",
      "2021-12-31: 24470.0\n",
      "2020-12-31: 24145.0\n",
      "2019-12-31: 23853.0\n",
      "\n",
      ": Total current assets(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 25224.0\n",
      "2021-12-31: 24239.0\n",
      "2020-12-31: 20441.0\n",
      "2019-12-31: 15667.0\n",
      "\n",
      ": Selling general and administrative(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: 11248.0\n",
      "2022-12-31: 11248.0\n",
      "2021-12-31: 11324.0\n",
      "2020-12-31: 9696.0\n",
      "2019-12-31: 9765.0\n",
      "\n",
      ": Shareholder’s Equity(In $M)\n",
      "ticker: ABT\n",
      "2023: 40,299\n",
      "2024: 42,525\n",
      "2025: 44,355\n",
      "2026: 59,357\n",
      "2027: 66,612\n",
      "\n",
      ": Total liabilities(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 37533.0\n",
      "2021-12-31: 39172.0\n",
      "2020-12-31: 39545.0\n",
      "2019-12-31: 36586.0\n",
      "\n",
      ": Basic average shares(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: \n",
      "2022-12-31: \n",
      "2021-12-31: 1764.082\n",
      "2020-12-31: 1771.23\n",
      "2019-12-31: 1762.503\n",
      "\n",
      ": Total cash(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 10170.0\n",
      "2021-12-31: 10249.0\n",
      "2020-12-31: 7148.0\n",
      "2019-12-31: 4140.0\n",
      "\n",
      ": Total revenue(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: 43653.0\n",
      "2022-12-31: 43653.0\n",
      "2021-12-31: 43075.0\n",
      "2020-12-31: 34608.0\n",
      "2019-12-31: 31904.0\n",
      "\n",
      ": Net income available to common shareholders(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: 6933.0\n",
      "2022-12-31: 6933.0\n",
      "2021-12-31: 7071.0\n",
      "2020-12-31: 4495.0\n",
      "2019-12-31: 3687.0\n",
      "\n",
      ": 124\n",
      "headline: BTIG Maintains Abbott Laboratories (ABT) Buy Recommendation\n",
      "final_score: 90\n",
      "datetime: 2023-04-17 16:40:11\n",
      "\n",
      ": Diluted average shares(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: \n",
      "2022-12-31: \n",
      "2021-12-31: 1789.0\n",
      "2020-12-31: 1786.0\n",
      "2019-12-31: 1781.0\n",
      "\n",
      ": Net Profit Adjusted(In $M)\n",
      "ticker: ABT\n",
      "2023: 7,712\n",
      "2024: 8,055\n",
      "2025: 8,980\n",
      "2026: 9,924\n",
      "2027: 10,672\n",
      "\n",
      ": Free Cash Flow(In $M)\n",
      "ticker: ABT\n",
      "2023: 9,410\n",
      "2024: 8,856\n",
      "2025: 9,288\n",
      "2026: 10,262\n",
      "2027: 11,338\n",
      "\n",
      ": Other long-term liabilities(figures in $M)\n",
      "ticker: ABT\n",
      "2022-12-31: 3804.0\n",
      "2021-12-31: 3685.0\n",
      "2020-12-31: 3684.0\n",
      "2019-12-31: 3944.0\n",
      "\n",
      ": Dividend yield\n",
      "2022: 0.017\n",
      "2021: 0.013\n",
      "2020: 0.013\n",
      "2019: 0.015\n",
      "2018: 0.016\n",
      "ticker: ABT\n",
      "\n",
      ": Total operating expenses(figures in $M)\n",
      "ticker: ABT\n",
      "ttm: 16149.0\n",
      "2022-12-31: 16149.0\n",
      "2021-12-31: 16113.0\n",
      "2020-12-31: 14248.0\n",
      "2019-12-31: 14141.0\n",
      "\n",
      ": Net Profit (Adjusted)(In $M)\n",
      "ticker: ABT\n",
      "2023: 6,781\n",
      "2024: 7,454\n",
      "2025: 8,792\n",
      "2026: 11,255\n",
      "2027: -\n",
      "    Question: Is ABT a good buy?\n",
      "    Think step by step. If there is not sufficient information provided, just say you don't know.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1f62473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x.process_file_names(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0872edfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10356db0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m,inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ts/lib/python3.9/site-packages/pandas/core/generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1530\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "if df != None:\n",
    "    df.drop(['ticker'], axis=1, errors='ignore',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eec4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_db = FAISS.load_local('../data/entiredocument',OpenAIEmbeddings(openai_api_key= open_ai_params['openai_api_key']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978527c7",
   "metadata": {},
   "source": [
    "### Checking Yahoo Finance for streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6382b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import FAISS,Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebd47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import LLM_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LLM_analysis('ABT',open_ai_params,cohere_params,ai21_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ce30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.qachain(pinecone_db,'''Have ABT's payables increased since 2021?''')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb5301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa7f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ts/lib/python3.9/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e9ee17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinancial-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m pinecone_db \u001b[38;5;241m=\u001b[39m Pinecone\u001b[38;5;241m.\u001b[39mfrom_existing_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinancial-analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43moai\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'oai' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc6e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295eac6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
