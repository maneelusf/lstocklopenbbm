{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# use dolly-v2-12b if you're using Colab Pro+, using pythia-2.8b for Free Colab\n",
    "generate_text = pipeline(model=\"databricks/dolly-v2-2-8b\", \n",
    "                         torch_dtype=torch.float32, \n",
    "                         trust_remote_code=True,\n",
    "                         device_map=\"auto\")\n",
    "\n",
    "generate_text = pipeline(model=\"databricks/dolly-v2-12b\", \n",
    "                         torch_dtype=torch.float32, trust_remote_code=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07607102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "res = generate_text(\"Hello how are you?\")\n",
    "time_taken = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "res = generate_text(\"Explain the difference between coding and programming?\")\n",
    "time_taken = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95851fc1",
   "metadata": {},
   "source": [
    "### Creating an LLM prompt/Agent/Chain for any stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "60925449",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AI21_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [395], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m open_ai_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m512\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m : yaml_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLMS\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     18\u001b[0m cohere_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommand-xlarge-nightly\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2202\u001b[39m,\\\n\u001b[1;32m     19\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcohere_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m : yaml_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLMS\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOHERE_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m,\\\n\u001b[1;32m     20\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m     21\u001b[0m ai21_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj2-grande-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumResults\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m,\\\n\u001b[0;32m---> 22\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai21_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43myaml_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLLMS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAI21_API_KEY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxTokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m25\u001b[39m}\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStockLLM\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,ticker):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AI21_API_KEY'"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from langchain.llms import Cohere,OpenAI,AI21\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import SequentialChain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from fuzzywuzzy import fuzz,process\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "with open('./data/apis.yaml', 'r') as file:\n",
    "    yaml_data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "open_ai_params = {'max_tokens':512,'openai_api_key' : yaml_data['LLMS']['OPENAI_API_KEY']}\n",
    "cohere_params = {'model':'command-xlarge-nightly','max_tokens':2202,\\\n",
    "                 'cohere_api_key' : yaml_data['LLMS']['COHERE_API_KEY'],'temperature':0,\\\n",
    "                'k': 0}\n",
    "ai21_params = {'model':\"j2-grande-instruct\",'numResults':1,'temperature':0,\\\n",
    " 'topP':1,'ai21_api_key':yaml_data['LLMS']['AI21_API_KEY'],\"maxTokens\":25}\n",
    "\n",
    "class StockLLM:\n",
    "    def __init__(self,ticker):\n",
    "        self.ticker = ticker\n",
    "        \n",
    "    def stock_availability(self):\n",
    "        return self.ticker in os.listdir('./ticker')\n",
    "    \n",
    "    def sec_analysis_agent(self):\n",
    "        ### Get sec files\n",
    "        file_path = f'./ticker/{self.ticker}/fa/analysis_sec.txt'\n",
    "        try:\n",
    "            with open(file_path,'r') as f:\n",
    "                file = f.read()\n",
    "        except:\n",
    "            raise Exception('This file is unavailable')\n",
    "        return file\n",
    "    \n",
    "#     def news_agent(self):\n",
    "#         file_path = f'./ticker/\n",
    "    \n",
    "class llm_analysis:\n",
    "    def __init__(self,ticker,open_ai_params,cohere_params,ai21_params):\n",
    "        ### Requires both Cohere and OpenAI APIs\n",
    "        self.ticker = ticker\n",
    "        self.open_ai_params = open_ai_params\n",
    "        self.cohere_params = cohere_params\n",
    "        self.ai21_params = ai21_params\n",
    "        self.cohere_llm = Cohere(**self.cohere_params)\n",
    "        self.open_ai_llm = OpenAI(**self.open_ai_params)\n",
    "        self.ai21_llm = AI21(**self.ai21_params)\n",
    "        self.stockllm = StockLLM(self.ticker)\n",
    "    \n",
    "    def sec_chain_analysis(self):\n",
    "        ### Initally we need a good bullet point summary of the latest sec filings\n",
    "        \n",
    "        template = \"\"\"\n",
    "\"This is the sec summary of {stock}.\\n\n",
    "{summary}\\n\"\n",
    "Can you summarize the text into bullet points with numbers in detail. Be as detailed as possible:-\n",
    "\"\"\"\n",
    "        sec_template = PromptTemplate(template=template,input_variables = ['stock','summary'])\n",
    "        sec_chain = LLMChain(llm=self.cohere_llm, prompt=sec_template,output_key = 'sec_summary')\n",
    "        template = '''You are a financial analyst. Based on the below bullet points, can you further separate them into positive\n",
    "and negative news in bullet points. Please do not leave out any point and go step by step.\n",
    "{sec_summary}'''\n",
    "        pos_neg_template = PromptTemplate(template=template,input_variables = ['sec_summary'])\n",
    "        pos_neg_chain = LLMChain(llm=self.open_ai, prompt=pos_neg_template,output_key = 'sec_final_output')\n",
    "        overall_chain = SequentialChain(\n",
    "    input_variables = ['stock','summary'],\n",
    "    chains=[sec_chain,pos_neg_chain],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=['sec_final_output','sec_summary'],\n",
    "    verbose=True)\n",
    "        with get_openai_callback() as cb:\n",
    "            statement = overall_chain({'stock':self.ticker,'summary':self.stockllm.sec_analysis_agent()})\n",
    "            cb = {\"Total Tokens\": cb.total_tokens,\\\n",
    "                 \"Prompt Tokens\":cb.prompt_tokens,\\\n",
    "                 \"Completion Tokens\":cb.completion_tokens,\\\n",
    "                 \"Total Cost (USD)\": cb.total_cost}\n",
    "            statement['token_summary'] = cb\n",
    "        return statement\n",
    "    \n",
    "    def news_chain_analysis(self):\n",
    "        try:\n",
    "            train_data_set = pd.read_csv('./train/news_train.csv',delimiter = '\\t').to_dict('records')\n",
    "        except:\n",
    "            raise Exception(\"The training file does not exist\")\n",
    "        try:\n",
    "            test_data_set = pd.read_csv('./train/news_train.csv',delimiter = '\\t').to_dict('records')\n",
    "        except:\n",
    "            raise Exception(\"The training file does not exist\")\n",
    "        ### This is the example prompt for getting the sentiment buckets.\n",
    "        example_prompt = PromptTemplate(\n",
    "    input_variables=[\"headline\", \"Sentiment\"],\n",
    "    template=\"Example Input: {headline}\\nExample Output: {Sentiment}\")\n",
    "        example_selector_initial = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # This is the list of examples available to select from.\n",
    "    train_data_set, \n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    CohereEmbeddings(cohere_api_key = cohere_params['cohere_api_key']),\n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS, \n",
    "    # This is the number of examples to produce.\n",
    "    k=30\n",
    "    )\n",
    "        example_selector_following = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # This is the list of examples available to select from.\n",
    "    train_data_set, \n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    CohereEmbeddings(cohere_api_key = cohere_params['cohere_api_key']),\n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS, \n",
    "    # This is the number of examples to produce.\n",
    "    k=2\n",
    "    )\n",
    "        try:\n",
    "            test_data_set = pd.read_csv(f'./ticker/{self.ticker}/news/c_news.csv')[['headline','datetime']]\n",
    "        except:\n",
    "            raise Exception(f\"The news file of {self.ticker} does not exist\")\n",
    "        similar_prompt_initial = FewShotPromptTemplate(\n",
    "    # The object that will help select examples\n",
    "        example_selector=example_selector_initial,\n",
    "        # Your prompt\n",
    "        example_prompt=example_prompt,\n",
    "        # Customizations that will be added to the top and bottom of your prompt\n",
    "        prefix='''Generate a sentiment score of a headline\\n The outputs can only be \n",
    "        [Strongly Negative,Negative,Neutral,Positive,Strongly Positive]''',\n",
    "        suffix=\"Input: {Headline}\\nOutput:\",\n",
    "        # What inputs your prompt will receive\n",
    "        input_variables=[\"Headline\"],)\n",
    "        similar_prompt_following = FewShotPromptTemplate(\n",
    "    # The object that will help select examples\n",
    "        example_selector=example_selector_following,\n",
    "        # Your prompt\n",
    "        example_prompt=example_prompt,\n",
    "        # Customizations that will be added to the top and bottom of your prompt\n",
    "        prefix='''Generate a sentiment score of a headline\\n The outputs can only be \n",
    "        [Strongly Negative,Negative,Neutral,Positive,Strongly Positive]''',\n",
    "        suffix=\"Input: {Headline}\\nOutput:\",\n",
    "        # What inputs your prompt will receive\n",
    "        input_variables=[\"Headline\"],)\n",
    "        validation_dict = []\n",
    "        for x in test_data_set.to_records('dict'):\n",
    "            if x.index == 0:\n",
    "               # llm = self.cohere_llm(**self.cohere_ai_params)\n",
    "                pred = self.open_ai_llm(similar_prompt_initial.format(Headline = x['headline']))\n",
    "                validation_dict.append(pred)\n",
    "            else:\n",
    "               # llm = self.cohere_llm(**self.cohere_ai_params)\n",
    "                pred = self.open_ai_llm(similar_prompt_following.format(Headline = x['headline']))\n",
    "                validation_dict.append(pred)\n",
    "        test_data_set['sentiment_bucket'] = validation_dict\n",
    "        z = y.copy()\n",
    "        z['sentiment_bucket'] = [x.strip() for x in z['sentiment_bucket']]\n",
    "        df = pd.DataFrame({'Strongly Positive':[0.8,1],'Positive':[0.6,0.8],'Neutral':[0.5,0.51],'Negative':[0.2,0.4],\\\n",
    "                   'Strongly Negative':[0,0.2]}).T.reset_index()\n",
    "        df['index'] = df['index'].astype(str)\n",
    "        df.columns = ['index','lower_bound','higher_bound']\n",
    "        z = z.merge(df,left_on = 'sentiment_bucket',right_on = 'index',how = 'outer')\n",
    "\n",
    "        z['sentiment_score'] = [np.random.randint(x*100,y*100)/100 for x,y in zip(z['lower_bound'],z['higher_bound'])]\n",
    "        z['ticker'] = self.ticker\n",
    "        final_cols = ['ticker','headline','datetime','sentiment_bucket','sentiment_score']\n",
    "        z = z[final_cols] \n",
    "        return z\n",
    "    \n",
    "    def input_from_user(self,query):\n",
    "        template = \"\"\"\n",
    "\"\\n\n",
    "{summary}\\n\"\n",
    "Please predict sentiment classification of the above based on above text where sentiment can only be Strongly Positive, Positive, Strongly Negative, Negative, or Neutral. Only output the sentiment class, should be 1 or 2 words.:-\n",
    "\"\"\"\n",
    "        sec_template = PromptTemplate(template=template,input_variables = ['summary'])\n",
    "        return self.open_ai_llm(template.format(summary = query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "e55e1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = llm_analysis('GOOG',open_ai_params,cohere_params,ai21_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "94d5917a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNeutral'"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.input_from_user('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "0d2e8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y['datetime'] = y['datetime'].apply(lambda x:datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "b501c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "107bdb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6c19738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "007213b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strongly Positive'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' Strongly Positive'.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e9f5e481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(low = x*100,high = y*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "b2460102",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - relativedelta(months = 2)).strftime('%Y-%m-%d')\n",
    "df = openbb.stocks.ba.cnews('META',start_date = start_date,end_date = end_date)\n",
    "df = pd.DataFrame(df)[['related','datetime','headline','summary']]\n",
    "df['datetime'] = df['datetime'].apply(lambda x:datetime.fromtimestamp(x))\n",
    "stock_summary = pd.read_json('https://www.sec.gov/files/company_tickers.json').T\n",
    "stock_summary = stock_summary[['title','ticker']]\n",
    "stock_summary.columns = ['Company','Ticker']\n",
    "choices = list(stock_summary[stock_summary['Ticker'] == 'META'].values[0])\n",
    "result = pd.DataFrame([process.extract(headline, choices, limit=2) for headline in df['headline']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "64f3282f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Forecasting Toolkit is disabled. To use the Forecasting features please install the toolkit following the instructions here: https://docs.openbb.co/sdk/quickstart/installation/</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mForecasting Toolkit is disabled. To use the Forecasting features please install the toolkit following the instructions here: https://docs.openbb.co/sdk/quickstart/installation/\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Portfolio Optimization Toolkit is disabled. To use the Optimization features please install the toolkit following the instructions here: https://docs.openbb.co/sdk/quickstart/installation/</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mPortfolio Optimization Toolkit is disabled. To use the Optimization features please install the toolkit following the instructions here: https://docs.openbb.co/sdk/quickstart/installation/\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openbb_terminal.sdk import openbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "dbe0398d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-800 Flowers Com</td>\n",
       "      <td>FLWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1St Source Corp</td>\n",
       "      <td>SRCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1St United Bancorp Inc</td>\n",
       "      <td>FUBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Systems Corp</td>\n",
       "      <td>DDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3M Co</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>Zogenix Inc</td>\n",
       "      <td>ZGNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>Zoltek Companies Inc</td>\n",
       "      <td>ZOLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>Zumiez Inc</td>\n",
       "      <td>ZUMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>Zygo Corp</td>\n",
       "      <td>ZIGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>Zynga Inc</td>\n",
       "      <td>ZNGA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3044 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Ticker\n",
       "0          1-800 Flowers Com   FLWS\n",
       "1            1St Source Corp   SRCE\n",
       "2     1St United Bancorp Inc   FUBC\n",
       "3            3D Systems Corp    DDD\n",
       "4                      3M Co    MMM\n",
       "...                      ...    ...\n",
       "3039             Zogenix Inc   ZGNX\n",
       "3040    Zoltek Companies Inc   ZOLT\n",
       "3041              Zumiez Inc   ZUMZ\n",
       "3042               Zygo Corp   ZIGO\n",
       "3043               Zynga Inc   ZNGA\n",
       "\n",
       "[3044 rows x 2 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../ticker/stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "27964ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def return_query(query):\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "2cca9d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"\\n\\nquery\\n\"\\nPlease predict sentiment classification of the above based on above text where sentiment can only be Strongly Positive, Positive, Strongly Negative, Negative, or Neutral. Only output the sentiment class, should be 1 or 2 words.:-\\n'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_query('query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "3076761f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f149826d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ab2c23-9213-4763-8817-bcdce470647e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with ZipFile(\"ticker.zip\", 'r') as zObject:\n",
    "    zObject.extractall(\n",
    "        path=\"ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1af6ea3-2b5e-4c80-96e5-ab749ec9f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fab7ac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1519594345.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from src.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from src.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5822b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
